# The name of the bundle. run `databricks bundle schema` to see the full bundle settings schema.
bundle:
  # Do not modify the below line, this autogenerated field is used by the Databricks backend.
  uuid: 00f2c5c2-4496-47f0-ad46-428527bd1901

  name: bhf_project_1

variables:
  experiment_name:
    description: Experiment name for the model training.
    default: /Users/${workspace.current_user.userName}/${bundle.target}-bhf_project_1-experiment
  model_name:
    description: Model name for the model training.
    default: bhf_project_1-model
  catalog_name:
    description: The catalog name to save the trained model
    
include:
  # Resources folder contains ML artifact resources for the ML project that defines model and experiment
  # And workflows resources for the ML project including model training -> validation -> deployment,
  # feature engineering,  batch inference, quality monitoring, metric refresh, alerts and triggering retraining
  - ./resources/batch-inference-workflow-resource.yml
  - ./resources/ml-artifacts-resource.yml
  - ./resources/model-workflow-resource.yml
  - ./resources/feature-engineering-workflow-resource.yml
  # TODO: uncomment once monitoring inference table has been created
  # - ./resources/monitoring-resource.yml

# Deployment Target specific values for workspace
targets:
  dev:  # UC Catalog Name 
    mode: development
    default: true
    variables:
      catalog_name: bhf_dev
    workspace:
      # TODO: add dev workspace URL
      host: https://fe-vm-sharath-ml-ops.cloud.databricks.com

  staging:
    variables:
      catalog_name: bhf_staging
    workspace:
      host: https://fe-vm-sharath-ml-ops.cloud.databricks.com

  prod:
    variables:
      catalog_name: bhf_prod
    workspace:
      host: https://fe-vm-sharath-ml-ops.cloud.databricks.com

  test:
    variables:
      catalog_name: bhf_test
    workspace:
      host: https://fe-vm-sharath-ml-ops.cloud.databricks.com
